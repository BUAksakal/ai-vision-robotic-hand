# ğŸ¤– AI Vision Controlled Robotic Hand
**Bachelorâ€™s Final Thesis Project**

This project presents a real-time computer vision system that controls a 3D-printed robotic hand using AI-based detection and embedded control logic. The main objective was to bridge artificial intelligence and physical robotics by translating human hand movements into real robotic actions.

The system captures live video input and processes it using **Python**, **OpenCV**, and **YOLOv8** for real-time hand detection and tracking. To improve robustness, I created a custom dataset by manually capturing and labeling images under different lighting conditions and hand positions using **Roboflow**. Detected gestures are interpreted in Python and transmitted to an **Arduino** microcontroller through serial communication, enabling real-time control of servo motors driving the robotic hand.

A safety mechanism was implemented to automatically release the grip after a predefined timeout, preventing excessive force and protecting both hardware and users. This project demonstrates a full AI-to-robotics pipeline integrating **Computer Vision**, **Embedded Systems**, and **Humanâ€“Machine Interaction** in a practical, real-world application.

---

## ğŸ“¸ Project Visuals

### ğŸ“Š Custom Dataset Creation
To train the detection model, I captured and labeled my own images of the robotic hand. This custom dataset improved detection stability and allowed reliable performance in real-world scenarios.

![Dataset Samples](<img width="582" height="579" alt="Screenshot 2026-02-14 at 14 54 50" src="https://github.com/user-attachments/assets/95401d94-1dc1-4007-8350-c9a5c22e329e" />
)

### ğŸ¤– Hardware Setup
The robotic hand was fully 3D-printed and controlled via Arduino-driven servo motors. Real-time commands generated by the vision model were translated into physical movement.

![Hardware Setup](![WhatsApp Image 2026-02-14 at 14 48 22](https://github.com/user-attachments/assets/4c6ea731-d8ce-4fc5-9e6e-d5e200427175)
)

### ğŸ¥ Real-Time Detection Demo
The system performs end-to-end real-time processing, from perception to robotic actuation.

![Demo](

https://github.com/user-attachments/assets/a303b61d-2563-4fac-adb6-9d53a5245386

)

---

## ğŸ§± System Workflow

Camera Input  
â†“  
YOLO / OpenCV Detection  
â†“  
Gesture Interpretation (Python)  
â†“  
Serial Communication  
â†“  
Arduino Controller  
â†“  
Servo Motors â†’ Robotic Hand Movement

---

## ğŸ§  Technologies Used

### Software
- Python
- OpenCV
- YOLOv8
- Roboflow
- NumPy
- PySerial

### Hardware
- Arduino
- Servo Motors
- 3D-Printed Robotic Hand
- USB Camera

---

## ğŸ“ Academic Context

Developed as a **Bachelorâ€™s Final Thesis** in Electrical and Electronics Engineering, focusing on the practical integration of AI perception with real-time robotic control.

---

## ğŸ‘¨â€ğŸ’» Author

**Berke UÄŸur Aksakal**  
AI Engineering Masterâ€™s Student  
Deggendorf Institute of Technology
